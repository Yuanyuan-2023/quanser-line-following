import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import cv2
import os

# # âœ… è®¾ç½®æ•°æ®ç›®å½•
# DATA_DIR = r""
# CSV_PATH = os.path.join(DATA_DIR, "labels.csv")

# # âœ… è¯»å– CSV å¹¶æ£€æŸ¥æ•°æ®æ˜¯å¦åˆç†
# df = pd.read_csv(CSV_PATH)

# if "image_filename" not in df.columns or "normalized_label" not in df.columns:
#     raise ValueError("âŒ CSV æ–‡ä»¶ç¼ºå°‘ `image_filename` æˆ– `normalized_label` åˆ—")

# df.dropna(inplace=True)  # ç§»é™¤ NaN è¡Œ
# df['image_path'] = df['image_filename'].apply(lambda x: os.path.join(DATA_DIR, x))

# # ğŸš¨ ç¡®ä¿ `normalized_label` åœ¨ [-1, 1] ä¹‹é—´
# df['normalized_label'] = df['normalized_label'].clip(-1, 1)

# # âœ… å›¾åƒé¢„å¤„ç†
# transform = transforms.Compose([
#     transforms.ToPILImage(),
#     transforms.Resize((160, 320)),
#     transforms.Grayscale(num_output_channels=1),
#     transforms.ToTensor(),
#     transforms.Normalize(mean=[0.5], std=[0.5])
# ])

# âœ… åˆ›å»ºè‡ªå®šä¹‰ Dataset
class QBotDataset(Dataset):
    def __init__(self, dataframe, transform=None):
        self.dataframe = dataframe
        self.transform = transform

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        row = self.dataframe.iloc[idx]
        img_path = row['image_path']
        label = torch.tensor(float(row['normalized_label']), dtype=torch.float32)

        # ğŸš¨ ç¡®ä¿å›¾åƒæ–‡ä»¶å­˜åœ¨
        if not os.path.exists(img_path):
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {img_path}, è·³è¿‡æ­¤æ ·æœ¬")
            return None

        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)
        if img is None:
            print(f"âŒ OpenCV æ— æ³•è¯»å–å›¾åƒ: {img_path}, è·³è¿‡æ­¤æ ·æœ¬")
            return None
        
        if self.transform:
            img = self.transform(img)

        return img, label

# âœ… å®šä¹‰ CNN æ¨¡å‹
class QBotCNN(nn.Module):
    def __init__(self):
        super(QBotCNN, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv2d(1, 24, kernel_size=5, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(24, 36, kernel_size=5, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(36, 48, kernel_size=5, stride=2, padding=2),
            nn.ReLU(),
            nn.Conv2d(48, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU(),
            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),
            nn.ReLU()
        )
        self.fc_layers = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64 * 20 * 40, 100),
            nn.ReLU(),
            nn.Linear(100, 50),
            nn.ReLU(),
            nn.Linear(50, 10),
            nn.ReLU(),
            nn.Linear(10, 1)  # é¢„æµ‹åç§»é‡
        )

    def forward(self, x):
        x = self.conv_layers(x)
        x = self.fc_layers(x)

        # ğŸš¨ é˜²æ­¢ `NaN` ä¼ æ’­
        x = torch.where(torch.isnan(x), torch.zeros_like(x), x)
        x = torch.clamp(x, min=-1, max=1)  # é™åˆ¶èŒƒå›´ [-1, 1]
        
        return x

def image_preprocessor(image, device="cpu"):
    # å›¾åƒé¢„å¤„ç†  
    transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.Resize((160, 320)),
        transforms.Grayscale(num_output_channels=1),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.5], std=[0.5])
    ])
    return transform(image).unsqueeze(0).to(device)
